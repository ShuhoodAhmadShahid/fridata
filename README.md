# FRIDATA: AI-Powered Data Operations Platform

FRIDATA is a modern, production-grade MVP for automating data operations using Generative AI. It allows users to upload datasets (CSV/Excel), describe transformations in plain English, and execute them securely using a Python/Pandas backend.

![FRIDATA UI](/docs/screenshot.png) *(Note: Add a screenshot here if available)*

## ğŸš€ Features

- **Natural Language Transformation**: "Drop duplicates", "Convert date column", "Filter rows where sales > 500" - just ask.
- **AI Agent (Gemini Pro)**: Powered by Google's Gemini Pro via `instructor` for structured, validated planning.
- **Interactive Data Diff**: Visualize changes with a before/after split view, highlighting modified cells and dropped rows.
- **Safety First**:
    - **Schema Validation**: The AI validates column names and types before generating a plan.
    - **Dry-Run Mechanism**: Operations are tested on a small sample before full execution.
    - **Secure File Handling**: UUID-based filenames and strict size limits.
- **Modern Stack**: Built with FastAPI, React (Vite), Tailwind CSS, and Docker.

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework**: FastAPI (Python 3.11)
- **AI Integration**: Google Gemini Pro + `instructor` library
- **Data Processing**: Pandas
- **Validation**: Pydantic v2
- **Containerization**: Docker

### Frontend
- **Framework**: React 18 + TypeScript + Vite
- **Styling**: Tailwind CSS
- **HTTP Client**: Axios
- **Icons**: Lucide React

## ğŸ“‹ Prerequisites

- **Docker Desktop** (Running)
- **Git**
- **Google Gemini API Key** (Get one from [Google AI Studio](https://aistudio.google.com/))

## âš¡ Quick Start

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/ShuhoodAhmadShahid/fridata.git
    cd fridata
    ```

2.  **Configure Environment**
    Create a `.env` file in the root directory (or rename checks if one exists) and add your API key:
    ```properties
    # .env
    GEMINI_API_KEY=AIzaSy...YourKeyHere
    VITE_API_URL=http://localhost:8000/api
    ```

3.  **Run with Docker Compose**
    ```bash
    docker-compose up --build
    ```

4.  **Access the App**
    Open your browser and navigate to:
    [http://localhost:5173](http://localhost:5173)

## ğŸ“– Usage Guide

1.  **Upload Data**: Drag and drop a CSV or Excel file into the upload zone.
2.  **View Profile**: See column statistics and a preview of your raw data.
3.  **Chat with Data**: Type a command like:
    > "Clean this dataset by removing missing values in the 'price' column and converting 'date' to datetime format."
4.  **Review Plan**: The AI will propose a set of steps. Review them in the chat history.
5.  **Execute**: Click "Execute Plan". The system will process the data and generate a diff.
6.  **Download**: If satisfied, download the cleaned CSV file.

## ğŸ›¡ï¸ Architecture & Security

- **Agentic Workflow**: The AI doesn't touch the data directly. It generates a *plan* (JSON), which is executed by a deterministic Python engine.
- **Validation**: Every step generated by the AI is validated against the actual dataset schema (column existence, data types) before execution.
- **Isolation**: Docker containers ensure environment consistency and isolation.

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a pull request.

## ğŸ“„ License

MIT License. See [LICENSE](LICENSE) for details.
